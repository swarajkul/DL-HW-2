{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_TY8zHxY1LS"
      },
      "source": [
        "# Homework 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ntLqKt1I84q"
      },
      "source": [
        "# Step 2\n",
        "utilizing the \"QMNIST\" dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_BrJE-MSI-Kf"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKpUkd41Jtf4",
        "outputId": "ca366534-ce9d-4731-dfe8-659105e47280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-train-images-idx3-ubyte.gz to ./data/QMNIST/raw/qmnist-train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9704059/9704059 [00:00<00:00, 105126090.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/QMNIST/raw/qmnist-train-images-idx3-ubyte.gz to ./data/QMNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-train-labels-idx2-int.gz to ./data/QMNIST/raw/qmnist-train-labels-idx2-int.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 463024/463024 [00:00<00:00, 12778582.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/QMNIST/raw/qmnist-train-labels-idx2-int.gz to ./data/QMNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-test-images-idx3-ubyte.gz to ./data/QMNIST/raw/qmnist-test-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9742279/9742279 [00:00<00:00, 103770649.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/QMNIST/raw/qmnist-test-images-idx3-ubyte.gz to ./data/QMNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-test-labels-idx2-int.gz to ./data/QMNIST/raw/qmnist-test-labels-idx2-int.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 526800/526800 [00:00<00:00, 12804660.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/QMNIST/raw/qmnist-test-labels-idx2-int.gz to ./data/QMNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load QMNIST dataset and preprocess\n",
        "train_dataset = datasets.QMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.QMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A00skpJDS3r1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "1aTWwvPVSEQn",
        "outputId": "9e457b63-bdef-4ae5-d9a4-7d728019b22b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define labels map\n",
        "labels_map = {\n",
        "    0: \"0\",\n",
        "    1: \"1\",\n",
        "    2: \"2\",\n",
        "    3: \"3\",\n",
        "    4: \"4\",\n",
        "    5: \"5\",\n",
        "    6: \"6\",\n",
        "    7: \"7\",\n",
        "    8: \"8\",\n",
        "    9: \"9\"\n",
        "}\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load QMNIST dataset\n",
        "train_dataset = datasets.QMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Create a figure to plot\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "\n",
        "# Iterate over the dataset and plot samples\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
        "    img, label = train_dataset[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "0bu-_rukSu77",
        "outputId": "bef34af7-4aa6-4901-a08f-b8f000906487"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAKSCAYAAABMVtaZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzlElEQVR4nO3de5iVZb0//nuBB0RAFA8XIIZkSGwrE8sEBNECLCWxwUzykGwFaVOoHUwyhCJTLi3aZoKxTQtTBFGxyLBQ8QCyI7cCziYxNQXjoIAIw2Fmfn98O/zaPfeCNayZtWbdr9d19Uefm896Pq5ZD7594L5Xrr6+vj4AAFDxWpR6AAAAmobgBwCQCMEPACARgh8AQCIEPwCARAh+AACJEPwAABIh+AEAJELwAwBIhOAHAJAIwa8MLF++PAwbNix069YttG7dOhx66KGhX79+Ye7cuaUeDSrK73//+zB48ODQrl270LZt2zBw4MDw3HPPlXosqCgXX3xxyOVy0f+98cYbpR4xaTnf1Vt6v/rVr8IPf/jDcPLJJ4dOnTqFrVu3htmzZ4eFCxeGqVOnhssuu6zUI0Kzt3Tp0tCnT5/QpUuXMHLkyFBXVxduvfXW8NZbb4Vnn302HHvssaUeESrCM888E1atWvVPtfr6+jBq1KjQtWvXsHz58hJNRgiCX9mqra0NvXr1CjU1NaG6urrU40Cz96lPfSo888wz4Y9//GPo0KFDCCGENWvWhO7du4eBAweG2bNnl3hCqFxPPvlkOOWUU8KkSZPCNddcU+pxkuaPestUy5YtQ5cuXcLGjRtLPQpUhIULF4aPf/zjfw99IYTQsWPH0L9///Dwww+HLVu2lHA6qGx33313yOVy4fzzzy/1KMkT/MrIu+++G9avXx9WrVoVvv/974d58+aF008/vdRjQUXYvn17OOCAA/6l3rp167Bjx46wbNmyEkwFlW/nzp1h5syZoXfv3qFr166lHid5+5R6AP7hqquuClOnTg0hhNCiRYtwzjnnhFtuuaXEU0FlOPbYY8OiRYtCbW1taNmyZQghhB07doTFixeHEIK/cA6N5JFHHgkbNmwIw4cPL/UoBE/8ysrYsWPD/Pnzw5133hnOOOOMUFtbG3bs2FHqsaAijB49OqxcuTKMGDEirFixIixbtixceOGFYc2aNSGEELZt21biCaEy3X333WHfffcN5557bqlHIdjcUdYGDhwYNm7cGBYvXhxyuVypx4Fmb9y4cWHy5Mlh586dIYQQTjzxxDBo0KAwadKkMGfOnHD22WeXdkCoMFu2bAlHHHFEOO200xxRViY88StjVVVVYcmSJWHlypWlHgUqwqRJk8Jf/vKXsHDhwvD888+HJUuWhLq6uhBCCN27dy/xdFB5HnjggbB161Z/zFtG/B2/Mva3P3ratGlTiSeBynHwwQeHvn37/v3/P/roo+HII48MPXr0KOFUUJlmzJgR2rRpE4YMGVLqUfgrT/zKwNq1a/+ltnPnznDXXXeFAw44IPTs2bMEU0Hlu/fee8OSJUvC2LFjQ4sWfjuEYlq3bl149NFHw9ChQ0Pr1q1LPQ5/5YlfGRg5cmTYvHlz6NevX+jcuXN48803w4wZM0J1dXW46aabQps2bUo9IjR7TzzxRJg4cWIYOHBg6NChQ1i0aFG44447wuDBg8OXv/zlUo8HFefee+8Nu3bt8se8ZcbmjjJwzz33hOnTp4cXXnghbNiwIbRt2zb06tUrjBkzxuNxKJJVq1aF0aNHh6VLl4Z33nknHH300eGiiy4KV155Zdhvv/1KPR5UnJNPPjm8/PLLYfXq1X8/QonSE/wAABLhL7UAACRC8AMASITgBwCQCMEPACARgh8AQCIEPwCARAh+AACJ2ONv7sjlco05B5REOR5j6V6jErnXoGns7l7zxA8AIBGCHwBAIgQ/AIBECH4AAIkQ/AAAEiH4AQAkQvADAEiE4AcAkAjBDwAgEYIfAEAiBD8AgEQIfgAAiRD8AAASIfgBACRC8AMASITgBwCQCMEPACARgh8AQCIEPwCARAh+AACJEPwAABIh+AEAJELwAwBIhOAHAJAIwQ8AIBGCHwBAIgQ/AIBECH4AAIkQ/AAAEiH4AQAkYp9SD1BuDj300Ohar169MutDhw6N9uRyucx6jx49oj39+vXLrK9YsSLas2HDhoJ7fvCDH2TWq6uroz0AQPPliR8AQCIEPwCARAh+AACJEPwAABIh+AEAJELwAwBIRK6+vr5+j35h5FiS5ip2BMvNN98c7XnPe96TWc/3Fsbet3Lo2bp1a2b9u9/9brTn+uuvj641R3v48W9SlXavFVO+92bffffNrA8fPjza061bt8z6xRdfHO058sgjM+vLli2L9kycODGzPmvWrGhPOX4290Y5/vO416hEu7vXPPEDAEiE4AcAkAjBDwAgEYIfAEAiBD8AgEQku6v385//fGb9rrvuivY0ZOfs0qVLC+5pyHVOPPHEJrnOqFGjMuvTpk2L9pQzOw0bX4sW2f992bp162jPZz7zmcz6gAEDoj0XXnhhYYOVga5du0bXXnvttaYbpAm412gKp556ama9f//+0Z7rrrsusz5hwoSCe8qBXb0AAIQQBD8AgGQIfgAAiRD8AAASIfgBACRC8AMASESyx7nEjpLo0aNHtOf9739/Zv3FF1+M9sSOcym25cuXZ9bz/fM05DiXyy+/PLPuOJfiqbR7LfYZXLFiRVGvs2vXrsz6pk2boj2x45sacpTKhz/84eha7KiZyy67LNrzk5/8pOAZypl7rXmJHYsSQgjjx48vuCemIceilMNRKuX82XGcCwAAIQTBDwAgGYIfAEAiBD8AgEQIfgAAiUh2V285GzRoUGb9mmuuifb069cvs57vxxv7ma5bt67g61RXV0d7ypmdhsVx0EEHRdeefvrpzHpsl3wIIezcuTOz/sILL0R7Jk2alFmfM2dOtKeYjjnmmOjaU089lVl/8MEHoz35dvw2R+614si3c7Z///5Fu0457JwtZ+X82bGrFwCAEILgBwCQDMEPACARgh8AQCIEPwCARAh+AACJ2KfUA1S6vn37ZtbHjRsX7Ykd55Jvi3ZsLV/P+vXrM+tXXHFFtKe5HttC4zr33HOja/mObYm56aabMuv5jjQqtZdeeim69uqrrzbhJFSCBQsWZNbzHedCcU2YMKHUIzQKT/wAABIh+AEAJELwAwBIhOAHAJAIwQ8AIBF29TayCy64ILMe27kbQsO+/DnWc//990d7vvnNb2bW7dylUMcff3zBPW+++WZ0berUqXsxTWm0bds2unbfffdl1t/3vvc11jg0c6XevVvOO1qvu+666Jrd0LvniR8AQCIEPwCARAh+AACJEPwAABIh+AEAJELwAwBIhONcGll9fX1B9Ya8Vj7f/e53o2uObaFY8h0bdPnll2fWDzzwwGhPx44dM+uvvvpqYYM1oYsuuii6dsMNN2TWX3755WhP+/btM+sbN24sZCyaqcceeyyznu9YkoYcwZLvaJRyle89KOaxLc3xvdkTnvgBACRC8AMASITgBwCQCMEPACARgh8AQCJy9Xu4VTSXyzX2LEkZOnRodG3SpEmZ9R49ekR7Yj+f2bNnR3uqqqqia6loyE7pxtYc77VDDz00urZixYqCe375y19m1i+44IJoT1Ptdj377LMz6z/96U+jPe3atcusz58/P9ozZMiQzPr27dujPeXMvUaxFPuzFNsN3Vx39e7u/fHEDwAgEYIfAEAiBD8AgEQIfgAAiRD8AAASIfgBACTCcS5l6KijjsqsL1myJNpz2GGHZdbz/Xhjx7nMmTMnz3SVxRETje/000/PrOc7yiRm5syZ0bXzzjuv4NeLad++fXRt0aJFmfXu3bsXfJ3YexNCCAsWLCj49cqZe41CjR8/PrNe7GNWKu1z4DgXAABCCIIfAEAyBD8AgEQIfgAAiRD8AAASsU+pB+Bfvfbaa5n1UaNGRXvuv//+gq8T2wkMxfTUU09l1j/72c9Ge2655ZbM+hlnnBHtie0S/vnPfx7tOfLIIzPrH/vYx6I9Ddm9G7Nq1aqivRY0R6eeemp0rZi7dwcMGFC012ruPPEDAEiE4AcAkAjBDwAgEYIfAEAiBD8AgEQIfgAAiXCcSzMyZ86c6FrsS5nL8YvRSUtNTU1m/b777ov2xI5MOfPMM6M9p59+ekF1oPTGjx9f1NebMGFCZv2xxx4r6nWaM0/8AAASIfgBACRC8AMASITgBwCQCMEPACARufo93PaZy+Uaexb2QkN29S5dujSzfuKJJxZlpuagHHc9u9fiDjzwwOjacccd1yQz3HnnnZn12E7kEEJ4/fXXM+u9evWK9qxbt66wwcqcey1tCxYsyKyfeuqpRb3OgAEDMusp7erd3b3miR8AQCIEPwCARAh+AACJEPwAABIh+AEAJELwAwBIxD6lHoA9N3To0OhaQ45zmT179l7PBE3p3Xffja4tXry45DPE/O53v8usV9qRLaQt39EsxTy2xTE8e8cTPwCARAh+AACJEPwAABIh+AEAJELwAwBIhF29Zeg973lPZn3q1KnRnobscqquri64B1LQr1+/6Nr73//+gl9vxYoVezMOlJXYDt0FCxYU9TqPPfZYUV+P/8cTPwCARAh+AACJEPwAABIh+AEAJELwAwBIhOAHAJAIx7mUSI8ePaJr999/f2a9Q4cO0Z76+vrM+vLly6M9c+bMia5Bytq2bRtda9WqVcGvF7unoTnq379/0V4r35EtAwYMKNp1+AdP/AAAEiH4AQAkQvADAEiE4AcAkAjBDwAgEcnu6p00aVJm/eyzz472XHjhhZn1fF/afs0112TW8+3qzeVymfXYzt0QQti2bVtmfdiwYdEeINvxxx9fcM/cuXOja6+88krDh4ESGD9+fHTtuuuuK9p1JkyYULTXYs944gcAkAjBDwAgEYIfAEAiBD8AgEQIfgAAiRD8AAASUdHHueQ7MuUb3/hGZj3fkSlLliwpuKchR7PELF++PLoWO7alurq64OtA6s4888yCe7Zu3Rpd27Vr196MA43m1FNPzawX88iWEEIYMGBAZv2xxx4r6nXYPU/8AAASIfgBACRC8AMASITgBwCQCMEPACARFb2rN9+O1g0bNmTWO3ToEO2J7dDNpyE9r732WmY9tisqhBDWr19f8HUASNuCBQuK9loTJkyIrtm9Wz488QMASITgBwCQCMEPACARgh8AQCIEPwCARAh+AACJqOjjXPIZO3ZsZv3SSy+N9hx22GGZ9R49ekR7Lrjggsz6iy++GO2Jfdm7I1ugadxwww3Rtfvvv78JJ4G9N378+KK+Xuxoluuuu66o16FxeOIHAJAIwQ8AIBGCHwBAIgQ/AIBECH4AAInI1dfX1+/RL8zlGnsWaHJ7+PFvUu610uvevXt0Lbaj8fHHH4/2fO5zn9vbkZo991rpNOS9j33OQwhhwIABezENjW13P29P/AAAEiH4AQAkQvADAEiE4AcAkAjBDwAgEYIfAEAi9in1AADlZuXKldG1Tp06NeEksOfGjx9fcE/s2BZHtlQuT/wAABIh+AEAJELwAwBIhOAHAJAIwQ8AIBG5+j389uZUvsyatPjieGga7jVoGru71zzxAwBIhOAHAJAIwQ8AIBGCHwBAIgQ/AIBECH4AAInY4+NcAABo3jzxAwBIhOAHAJAIwQ8AIBGCHwBAIgQ/AIBECH4AAIkQ/AAAEiH4AQAkQvADAEiE4AcAkAjBDwAgEYIfAEAiBD8AgEQIfgAAiRD8ysDy5cvDsGHDQrdu3ULr1q3DoYceGvr16xfmzp1b6tGgovz+978PgwcPDu3atQtt27YNAwcODM8991ypx4KKcvHFF4dcLhf93xtvvFHqEZOWq6+vry/1EKn71a9+FX74wx+Gk08+OXTq1Cls3bo1zJ49OyxcuDBMnTo1XHbZZaUeEZq9pUuXhj59+oQuXbqEkSNHhrq6unDrrbeGt956Kzz77LPh2GOPLfWIUBGeeeaZsGrVqn+q1dfXh1GjRoWuXbuG5cuXl2gyQhD8ylZtbW3o1atXqKmpCdXV1aUeB5q9T33qU+GZZ54Jf/zjH0OHDh1CCCGsWbMmdO/ePQwcODDMnj27xBNC5XryySfDKaecEiZNmhSuueaaUo+TNH/UW6ZatmwZunTpEjZu3FjqUaAiLFy4MHz84x//e+gLIYSOHTuG/v37h4cffjhs2bKlhNNBZbv77rtDLpcL559/fqlHSZ7gV0befffdsH79+rBq1arw/e9/P8ybNy+cfvrppR4LKsL27dvDAQcc8C/11q1bhx07doRly5aVYCqofDt37gwzZ84MvXv3Dl27di31OMnbp9QD8A9XXXVVmDp1agghhBYtWoRzzjkn3HLLLSWeCirDscceGxYtWhRqa2tDy5YtQwgh7NixIyxevDiEEPyFc2gkjzzySNiwYUMYPnx4qUcheOJXVsaOHRvmz58f7rzzznDGGWeE2trasGPHjlKPBRVh9OjRYeXKlWHEiBFhxYoVYdmyZeHCCy8Ma9asCSGEsG3bthJPCJXp7rvvDvvuu28499xzSz0KweaOsjZw4MCwcePGsHjx4pDL5Uo9DjR748aNC5MnTw47d+4MIYRw4oknhkGDBoVJkyaFOXPmhLPPPru0A0KF2bJlSzjiiCPCaaed5oiyMuGJXxmrqqoKS5YsCStXriz1KFARJk2aFP7yl7+EhQsXhueffz4sWbIk1NXVhRBC6N69e4mng8rzwAMPhK1bt/pj3jLi7/iVsb/90dOmTZtKPAlUjoMPPjj07dv37///0UcfDUceeWTo0aNHCaeCyjRjxozQpk2bMGTIkFKPwl954lcG1q5d+y+1nTt3hrvuuisccMABoWfPniWYCirfvffeG5YsWRLGjh0bWrTw2yEU07p168Kjjz4ahg4dGlq3bl3qcfgrT/zKwMiRI8PmzZtDv379QufOncObb74ZZsyYEaqrq8NNN90U2rRpU+oRodl74oknwsSJE8PAgQNDhw4dwqJFi8Idd9wRBg8eHL785S+XejyoOPfee2/YtWuXP+YtMzZ3lIF77rknTJ8+Pbzwwgthw4YNoW3btqFXr15hzJgxHo9DkaxatSqMHj06LF26NLzzzjvh6KOPDhdddFG48sorw3777Vfq8aDinHzyyeHll18Oq1ev/vsRSpSe4AcAkAh/qQUAIBGCHwBAIgQ/AIBECH4AAIkQ/AAAEiH4AQAkQvADAEjEHn9zRy6Xa8w5oCTK8RhL9xqVyL0GTWN395onfgAAiRD8AAASIfgBACRC8AMASITgBwCQCMEPACARgh8AQCIEPwCARAh+AACJEPwAABIh+AEAJELwAwBIhOAHAJAIwQ8AIBGCHwBAIgQ/AIBECH4AAIkQ/AAAEiH4AQAkQvADAEiE4AcAkAjBDwAgEYIfAEAiBD8AgEQIfgAAiRD8AAASIfgBACRC8AMASITgBwCQCMEPACARgh8AQCL2KfUAjalXr17RtTPOOCOzftVVV0V72rdvv7cj7ZW77roruvbUU09l1qdNm9ZY4wAAzYwnfgAAiRD8AAASIfgBACRC8AMASITgBwCQCMEPACARufr6+vo9+oW5XGPPUnSXX355dO1HP/pRE07S+GI/xtWrV0d7Bg0alFlfsWJFUWZqDvbw49+kmuO9BrvjXqO5+dCHPhRd+8AHPpBZr6qqivbsv//+mfUpU6ZEe379619H12J2d6954gcAkAjBDwAgEYIfAEAiBD8AgEQIfgAAidin1ANQHLHdaZ07d472zJ49O7P+/ve/vygzQbENGDAgujZx4sTMet++faM9xdxpevXVV0fXbrzxxqJdBwq1zz7xf9V/5jOfyawPGzYs2vPiiy9m1ufOnVvYYLsR+/faCSecEO3p0aNHwdeJ/b7SvXv3aM++++5b8HVi1q1bF11ryK7e3fHEDwAgEYIfAEAiBD8AgEQIfgAAiRD8AAASIfgBACQiV7+H5xk0xy+zbtWqVXTtlFNOyazPmjUr2rN27drM+m9+85toz49//OPM+urVq6M9Rx11VGZ93Lhx0Z7Ylvx8amtrM+sXXnhhtOcXv/hFwdcpZ744vjx96UtfyqxPnjw52hM7siLf+1nMn//OnTujaxMmTMisX3/99UW7frlzrzW+2BEjP/jBD6I9o0aNyqw31X2TT2yGUl+/oTPEMsTo0aOjPXPmzCn4OrubzRM/AIBECH4AAIkQ/AAAEiH4AQAkQvADAEhERe/qbYjDDz88uhbbtff222831jj/JN+XQse+HHvgwIEFX2fEiBHRtTvuuKPg1ytndhqWTr7P2a233ppZz/dl87Ed+a+++mq0Z+bMmZn19773vdGe8ePHZ9bzfTn8G2+8kVnv3bt3tOfPf/5zdK05cq81vv/4j//IrE+ZMqXg1yr2jtaamprM+tatWwueYcmSJdGe//7v/86sH3TQQdGeL37xiwVdP4T4e7Bq1apozyc+8YnMer7foxrCrl4AAEIIgh8AQDIEPwCARAh+AACJEPwAABIh+AEAJCJ+NkKiYl+iXA7yfQn89u3bC369LVu2ZNbzbUeHYpk4cWJ0LXZsy9KlS6M9l19+eWb9rbfeKmywED8SIoQQnnjiicx67MiWEELo1KlTZv2RRx6J9lx66aWZ9aeeeiraQ+U79thjo2tjxoxpkhk2bNiQWR89enS0Z9myZZn16urqosz0N0OGDMms33TTTUW9Tuz3iJEjR0Z7in1sS0N54gcAkAjBDwAgEYIfAEAiBD8AgEQIfgAAibCrN2ELFizIrMd2LUIxxXa6hhD/kvHYZzaEhu3ebYg1a9Zk1mO7ikMI4cc//nFmvUePHtGehQsXZtZbtPDf6yn74he/GF173/veV7TrrF+/Prp22mmnZdZjO3eL7eqrr46ufeMb38ist23btuDr5HsPRowYkVlvqvdgb/gdBAAgEYIfAEAiBD8AgEQIfgAAiRD8AAASIfgBACTCcS4l8tGPfjS6dt555xX8ev379y+455577im4B4oldmRLvrUvfOEL0Z5p06Zl1l966aXCBmugt99+O7qW75815vbbb9+bcahQDblv8nnkkUcy61/72teiPU11ZMnkyZMz61dccUW0J5fLZdYb8t7EjmEKoXkc2xLjiR8AQCIEPwCARAh+AACJEPwAABIh+AEAJCJXv4dbXWI7ZWiYAQMGRNd++9vfFu068+fPj6597nOfy6w31Zfdl4OG7PRqbKnca9/73veia1/96lcLfr0//elPmfXbbrst2rNq1arMerdu3aI9sbXY/RRCCAcddFBm/Y033oj29OzZM7O+ZcuWaE85c68Vx/Tp06NrH/rQhzLrs2bNivb88Ic/zKxv3bq1sMEaqE+fPtG1hQsXZtYb8lmqq6uLrn3zm9/MrN96663RnnfeeafgGZrK7t4fT/wAABIh+AEAJELwAwBIhOAHAJAIwQ8AIBGCHwBAIhznUiLHH398dC325ey9evWK9rz55puZ9dNOOy3aU11dHV1LhSMmSqdDhw7Rte9+97uZ9aqqqmhP+/btM+v53s9i/vzzXSd2RNInP/nJaM+zzz671zOVE/da2vr27ZtZf+ihh6I9sXu6IZ+l8ePHR9e+853vFPx65cxxLgAAhBAEPwCAZAh+AACJEPwAABIh+AEAJMKu3jJ03HHHZdYff/zxaM/BBx9ccM+5556bWV+3bl2e6SqLnYbNy5lnnhldK+au3ny7bc8777yCrxP7EvhJkyZFeyqNe63yderUKbq2bNmyzPpBBx0U7Yn9fPJ9lmL31E033RTt2bRpU3StObKrFwCAEILgBwCQDMEPACARgh8AQCIEPwCARAh+AACJcJxLMzJkyJDo2k9/+tPMeuyIixBC+PrXv55Znzx5ciFjNWuOmEhbx44dM+uLFi2K9hx55JGZ9QcffDDaU1VVlVmvq6vLM11lca9Vjve+972Z9aVLl0Z72rZtW/B1Yj+fr3zlK9GefMe2pMJxLgAAhBAEPwCAZAh+AACJEPwAABIh+AEAJGKfUg/AnnvooYeiaxdddFFm/cYbb4z2fOtb38qsr169OtozY8aM6Bo0N5dffnlmPbZzN4QQVqxYkVn/zne+E+1JafculaFnz57RtTvuuCOz3qZNm2hPQ3Z1f/WrX82s33zzzQW/Fv/giR8AQCIEPwCARAh+AACJEPwAABIh+AEAJELwAwBIRK5+D/dY+zLr5unYY4+Nrr344ouZ9TfeeCPa06VLl72eqZz44vjK16tXr+jak08+mVnfb7/9oj0TJ07MrE+YMKGwwRLjXitPbdu2zazfeuut0Z7zzz+/aNefNGlSdC125Bj57e5e88QPACARgh8AQCIEPwCARAh+AACJEPwAABKxT6kHoHFVVVUV3NO+ffvo2umnn55Z/+1vf1vwdaApfPnLX46u7b///pn1+++/P9pj9y7NTbt27aJrc+fOzayfcsop0Z7YrtG6urpoT01NTWZ9w4YN0R4ahyd+AACJEPwAABIh+AEAJELwAwBIhOAHAJAIwQ8AIBGOc6kQPXv2zKyPGDGi4Nc68MADo2vHHHNMZt1xLpRa7KihfEcaxY6luO+++4oyEzSltm3bZtZjR7aEEELfvn2Ldv1169ZF16ZNm5ZZ37x5c9Guz57xxA8AIBGCHwBAIgQ/AIBECH4AAIkQ/AAAEmFXb4nsu+++0bUPfOADmfV///d/j/YMHjw4s961a9eC5gohhI0bN0bXFi5cWPDrQbG0aBH/b9VvfvObmfVWrVpFe+bMmZNZf/DBBwsbDJpI+/bto2ux3bt9+vQp+Dq5XK6oPe+++25m/Y477ij4OuwdT/wAABIh+AEAJELwAwBIhOAHAJAIwQ8AIBGCHwBAIhzn8n/kO2Yl37EQhZowYUJ0bezYsUW7Tj51dXWZ9RkzZkR7VqxY0VjjwG5dc8010bV+/foV/HpPP/10Zr2mpqbg14KmMG7cuOha7969M+v19fVFneGdd97JrF9yySXRnnnz5hV1BhrOEz8AgEQIfgAAiRD8AAASIfgBACRC8AMASERF7+r92Mc+Fl0bOnRoZr1nz57Rnk996lN7PdPeiO3CDSG+a2vXrl3Rnp/85CeZ9TFjxhQ2GDSRYcOGRddiXxA/f/78aM+PfvSjvZ4JGkPs3zcjRoxokuu/9NJL0bWRI0dm1hcsWNBY41BEnvgBACRC8AMASITgBwCQCMEPACARgh8AQCIEPwCARFT0cS47d+6Mrm3evDmz3qdPn8YaZ6/deOON0bVHHnkks/7444831jjQaGLHKvXo0SPaEzvS6D//8z+jPTU1NYUNBk3knHPOyawfdNBBRb3OCy+8kFn/+te/Hu1xbEvz5okfAEAiBD8AgEQIfgAAiRD8AAASIfgBACQiVx/bCvd/f2HkC9ChOdvDj3+Tcq+FcN5552XWZ8yYEe1ZunRpZv0jH/lIUWZi77jXCnPYYYdl1q+//vpoT1VVVWY93y7cSy+9NLO+fv36PNNRznZ3r3niBwCQCMEPACARgh8AQCIEPwCARAh+AACJEPwAABLhOBeS5oiJ8nT55Zdn1r/97W9He7p3755Zf+utt4oyE3vHvQZNw3EuAACEEAQ/AIBkCH4AAIkQ/AAAEiH4AQAkwq5ekmanITQN9xo0Dbt6AQAIIQh+AADJEPwAABIh+AEAJELwAwBIhOAHAJCIPT7OBQCA5s0TPwCARAh+AACJEPwAABIh+AEAJELwAwBIhOAHAJAIwQ8AIBGCHwBAIgQ/AIBECH4AAIkQ/AAAEiH4AQAkQvADAEiE4AcAkAjBrwxs3749fP3rXw+dOnUKBxxwQDjppJPC/PnzSz0WVJTly5eHYcOGhW7duoXWrVuHQw89NPTr1y/MnTu31KNBRXGvlTfBrwxcfPHF4eabbw7Dhw8PU6ZMCS1btgyf/OQnw5NPPlnq0aBivPrqq+Gdd94JF110UZgyZUq49tprQwghDBkyJEybNq3E00HlcK+Vt1x9fX19qYdI2bPPPhtOOumkMHny5PCVr3wlhBBCTU1NOO6448Lhhx8enn766RJPCJWrtrY29OrVK9TU1ITq6upSjwMVy71WPjzxK7FZs2aFli1bhssuu+zvtVatWoURI0aEZ555Jvz5z38u4XRQ2Vq2bBm6dOkSNm7cWOpRoKK518rHPqUeIHV/+MMfQvfu3UO7du3+qf7Rj340hBDCc889F7p06VKK0aAivfvuu2Hbtm1h06ZN4aGHHgrz5s0Ln/3sZ0s9FlQc91p5EvxKbM2aNaFjx47/Uv9bbfXq1U09ElS0q666KkydOjWEEEKLFi3COeecE2655ZYSTwWVx71WngS/Etu2bVvYf//9/6XeqlWrv68DxTN27NhQVVUVVq9eHWbOnBlqa2vDjh07Sj0WVBz3WnmyuaPEjjvuuHDEEUeE3/72t/9UX7FiRfi3f/u3cNttt4WRI0eWaDqofAMHDgwbN24MixcvDrlcrtTjQMVyr5UHmztKrGPHjmHNmjX/Uv9brVOnTk09EiSlqqoqLFmyJKxcubLUo0BFc6+VB8GvxI4//viwcuXKsHnz5n+qL168+O/rQOP521+n2LRpU4kngcrmXisPgl+JVVVVhdra2n861HL79u3hjjvuCCeddJIdvVAka9eu/Zfazp07w1133RUOOOCA0LNnzxJMBZXHvVbebO4osZNOOikMGzYsfOMb3whr164NxxxzTLjzzjvDK6+8EqZPn17q8aBijBw5MmzevDn069cvdO7cObz55pthxowZobq6Otx0002hTZs2pR4RKoJ7rbzZ3FEGampqwrXXXht+/vOfh7fffjt88IMfDN/+9rfDoEGDSj0aVIx77rknTJ8+Pbzwwgthw4YNoW3btqFXr15hzJgxYciQIaUeDyqGe628CX4AAInwd/wAABIh+AEAJELwAwBIhOAHAJAIwQ8AIBGCHwBAIgQ/AIBE7PE3d+RyucacA0qiHI+xdK9Ridxr0DR2d6954gcAkAjBDwAgEYIfAEAiBD8AgEQIfgAAiRD8AAASIfgBACRC8AMASITgBwCQCMEPACARgh8AQCIEPwCARAh+AACJEPwAABIh+AEAJELwAwBIhOAHAJCIfUo9QHPSv3//zPoVV1wR7RkyZEhm/eqrr4723HjjjYUNBolo06ZNdG3evHmZ9W7dukV77rvvvsz6LbfcEu156aWXomsA5c4TPwCARAh+AACJEPwAABIh+AEAJELwAwBIhOAHAJCIXH19ff0e/cJcrrFnKQuDBw+Ort1zzz2Z9Xbt2kV76urqMus7duyI9nz729/OrF9//fXRHhpmDz/+TSqVe60hDjnkkOjaunXrMuv53s/Yz7+mpibac++992bWb7vttmjPs88+G11LhXsNmsbu7jVP/AAAEiH4AQAkQvADAEiE4AcAkAjBDwAgEcnu6m3btm1mfc6cOdGeU089NbPeokU8P8d29ebz+uuvZ9a7du0a7bn66qsz63/4wx+iPU899VRmfcuWLfHhKoydhs1Ly5Yto2tf+MIXMuv53s/nn38+sz5t2rRoz3HHHRddixk1alRmffr06dGehvzeUc7ca83LsGHDomu33357Zj3fCRex9zrfPXDllVdm1jdv3hztwa5eAAD+SvADAEiE4AcAkAjBDwAgEYIfAEAiBD8AgEQke5zLj3/848z6pZdeWvBrvfvuu9G1sWPHZtbzbUffunVrZn3evHnRntjRD/mOhBg6dGhm/dFHH432bNu2LbrWHDligiytWrWKrsWOuZgwYUK0J3YUU77fb376059m1mtra6M95cy9Vp6uvfbazPrXvva1aE/syLH58+dHe9asWVPwdWLHkQ0ZMiTak9JxZDGOcwEAIIQg+AEAJEPwAwBIhOAHAJAIwQ8AIBH7lHqAxvShD30ounbmmWcW7TpnnXVWdO2JJ54o2nWKbc6cOZn1u+++O9pz4YUXNtY4UDZqamqiaz/72c8y6/l2vM+cOTOzPm3atGjPq6++mlnPt+seCrV+/frM+gMPPBDtueSSSzLrO3fuLPj6Rx55ZHRt1KhRmfXBgwdHe2bNmlXwDKnxxA8AIBGCHwBAIgQ/AIBECH4AAIkQ/AAAEiH4AQAkoqKPc3n44Yeja507dy749a688srMejkc2TJgwIDM+ty5c6M9bdq0yaznO+rmiiuuyKx///vfzzMdVL58x0jMmDEjsz58+PBoT58+fTLrjnOhmGLHuZx//vnRnldeeSWzfu211xZ8/SlTpkTXYse5sHc88QMASITgBwCQCMEPACARgh8AQCIEPwCARFTErt5LL700s3744YdHe+rq6jLra9asifb85Cc/KWywJvT4449n1ocNGxbtiX3Z/CGHHBLtmTx5cmb9hBNOiPb86Ec/yqwvWrQo2gPNTb4vjj/xxBMz6/X19dGe2G5LgL3hiR8AQCIEPwCARAh+AACJEPwAABIh+AEAJELwAwBIREUc59KmTZvMesuWLQt+rdra2ujali1bCn69UnvkkUeiaxdddFFm/c4774z2xI56yfdl84MGDSro+iGEMG/evOgaNLbjjjsuuhb78voxY8ZEew488MDMeuyooxBCmDZtWnQNiuU3v/lNZn3gwIHRnldffbVo199vv/2K9lrsGU/8AAASIfgBACRC8AMASITgBwCQCMEPACARufp83xL+//+FuVxjz9JgV1xxRWZ98uTJBb/W66+/Hl3r2rVrwa/XHMV24YYQwtSpUzPrRx11VLSnrq4us/7WW29Fey644ILMer5dyg2xhx//JlXO91pTie3IP+igg6I9Rx99dGa9d+/e0Z6qqqrM+kc+8pFoT2wX4v333x/tmTVrVsE9u3btiq41R+41sjz99NPRtYMPPjizftppp0V71qxZs9czNXe7u9c88QMASITgBwCQCMEPACARgh8AQCIEPwCARAh+AACJ2KfUA1B+8h2ZEjvSZs6cOdGes846K7N+yCGHRHtix8akcqRO6i655JLM+m233Vbwa+U7siN27MFDDz0U7fnFL36RWZ85c2Zhg0FCHnjggcz6Bz7wgWhPnz59MuuObNk7nvgBACRC8AMASITgBwCQCMEPACARgh8AQCIqeldvixaF51pf2t0wTzzxRHTt05/+dMGv165du8z6CSecEO1ZunRpwdehPK1YsSKz/rvf/S7ac/rpp2fW893T//u//5tZHz58eLRn69at0TVIQcuWLTPrEydOjPYMGTIksz5+/Phoz/PPP1/YYOwRT/wAABIh+AEAJELwAwBIhOAHAJAIwQ8AIBGCHwBAIir6OJe6urqCe2Jf2k5+t99+e3Tt4x//eGZ90KBB0Z7YcS6nnHJKtMdxLpXjqaeeyqwPHDgw2vPhD384sz5jxoxoT/fu3TPrL774YrRn6NChmXWfPyrJ2LFjo2uf+cxnMuu9e/eO9syaNSuzfuONNxY0F3vPEz8AgEQIfgAAiRD8AAASIfgBACRC8AMASERF7+ql6WzZsiW6tmDBgsx6vl29a9euzazfe++9hQ1GRcm36z62q7ZXr17Rntjn6ZOf/GS055e//GVmPd+O85deeim6BqU0bNiwzPrNN99c1Ovkcrmivh4N54kfAEAiBD8AgEQIfgAAiRD8AAASIfgBACRC8AMASITjXCiK4cOHR9fGjx9f8Ovt2LEjs/7mm28W/FoUT+xIhhNOOCHa07dv38z6lClTijLT7mzdujW69rnPfS6z/oc//CHa061bt8z6lVdeGe0ZPXp0dA1K6YUXXsisjxs3ruDXeu973xtdu+SSSzLrrVq1ivZcffXVmfXly5cXNhj/xBM/AIBECH4AAIkQ/AAAEiH4AQAkQvADAEiEXb3/R/v27aNr/fr1y6w/8cQTjTRN+fn0pz+dWf/Zz34W7amrqyv4Og8++GDBPTS+q666KrN+ww03RHtuu+22xhpnr23ZsiWzHvvi+hBC+M1vfpNZHzlyZLTnxhtvzKy/8sor8eGgCVRXV2fWr7/++qJe5+GHH86s/9d//Ve059e//nVmvX///tGel19+ubDBEuSJHwBAIgQ/AIBECH4AAIkQ/AAAEiH4AQAkQvADAEhErr6+vn6PfmHky9nLWb4jRoYPH17w68WOGBk6dGjBr1UOzjvvvMx6jx49oj3f+ta3Muv5Ph+xj9j3vve9aM8111wTXSumPfz4N6lS32utW7eOri1dujSzvmTJkmjPBRdcsNczlZNFixZl1j/60Y9Ge2LvwYwZM4oyU3PgXiPLJz7xieha7DiXW2+9NdozZsyYvZ6pudvdveaJHwBAIgQ/AIBECH4AAIkQ/AAAEiH4AQAkYp9SD9CYLrvssuhabOfqhz/84WjPWWedlVn/85//HO257rrrMutz5syJ9mzbti2zfuaZZ0Z7Yq699tro2jHHHJNZ32+//aI9dXV1mfUWLeL/DfHaa69l1vN9OTelM2TIkOja0UcfnVkv9he6N0fluGsVyt3vfve76Nrvf//7zPqll14a7YmdPPH2228XNlgF88QPACARgh8AQCIEPwCARAh+AACJEPwAABIh+AEAJKKij3OJHYsSQnzL95133hntOeSQQzLrnTt3jvZMnTo1s/6lL30p2rNjx47Mer6jZmLHqcSOXym2X/ziF9G18ePHZ9ZfeumlxhqHvdCxY8foWuyz+T//8z+NNc5eO+KII6JrseNpvvrVr0Z7PvjBD2bW33nnnWhPOb8/UEq1tbXRtV27dmXWX3/99WjP9u3b93qmSueJHwBAIgQ/AIBECH4AAIkQ/AAAEiH4AQAkIle/h98snsvlGnuWsjBo0KDoWmyHbrt27aI9+daKqSG7emM7NNeuXRvtefDBBzPr06dPj/Y8//zz0bVS28OPf5Mq9b3WqlWr6NqTTz6ZWT/qqKMK7lmwYEG0p02bNpn1/fffP9oT2217yimnRHtiO/XzWbduXWa9qqoq2hN7D1LiXiuds88+O7q2zz7Zh3vMmjWrkab5Z717946uzZ07N7M+ceLEaM+UKVP2eqbmbnf3mid+AACJEPwAABIh+AEAJELwAwBIhOAHAJAIwQ8AIBGOcymCK664Iro2efLkJplh4cKFmfUHHngg2rNmzZrM+syZM4sxUrPgiInCHHPMMZn1b33rW9Gez3/+85n1pnrvn3766ejan/70p8z6Qw89FO2ZP39+Zn3Tpk2FDZYY91rpfOxjH4uunXXWWZn1cePGFXydww47LLoWO4LlvPPOi/bE7s98Rye9/PLL0bVUOM4FAIAQguAHAJAMwQ8AIBGCHwBAIgQ/AIBE2NVL0uw0hKbhXiudli1bRteuu+66zPqpp54a7WnVqlVmvXPnztGegw8+OLP+ve99L9pzww03ZNZramqiPdjVCwDAXwl+AACJEPwAABIh+AEAJELwAwBIhOAHAJAIx7mQNEdMQNNwr5Wnww8/PLN+++23R3tOO+20zPqsWbOiPVOmTMmsP/fcc/HhaBDHuQAAEEIQ/AAAkiH4AQAkQvADAEiE4AcAkAi7ekmanYbQNNxr0DTs6gUAIIQg+AEAJEPwAwBIhOAHAJAIwQ8AIBGCHwBAIgQ/AIBECH4AAIkQ/AAAEiH4AQAkQvADAEiE4AcAkAjBDwAgEYIfAEAiBD8AgEQIfgAAiRD8AAASIfgBACRC8AMASESuvr6+vtRDAADQ+DzxAwBIhOAHAJAIwQ8AIBGCHwBAIgQ/AIBECH4AAIkQ/AAAEiH4AQAkQvADAEjE/wfcMUFEESPrDgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create a figure to plot\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "\n",
        "# Iterate over the test dataset and plot samples\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(test_dataset), size=(1,)).item()\n",
        "    img, label = test_dataset[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eBt_6_T0JxRZ"
      },
      "outputs": [],
      "source": [
        "# Define the neural network architecture\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the neural network\n",
        "model = MLP()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7LOPbrkJ3Pi",
        "outputId": "732e8fa6-b07f-4568-d9f8-f9971dd6c187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 1.0337111470103264\n",
            "Epoch 1, Batch 200, Loss: 0.4386751553416252\n",
            "Epoch 1, Batch 300, Loss: 0.4141509573161602\n",
            "Epoch 1, Batch 400, Loss: 0.33490343898534775\n",
            "Epoch 1, Batch 500, Loss: 0.31445020735263823\n",
            "Epoch 1, Batch 600, Loss: 0.28450584813952445\n",
            "Epoch 1, Batch 700, Loss: 0.26106818273663523\n",
            "Epoch 1, Batch 800, Loss: 0.2644056344777346\n",
            "Epoch 1, Batch 900, Loss: 0.24439160391688347\n",
            "Epoch 2, Batch 100, Loss: 0.2142498016357422\n",
            "Epoch 2, Batch 200, Loss: 0.21004280984401702\n",
            "Epoch 2, Batch 300, Loss: 0.2012569072842598\n",
            "Epoch 2, Batch 400, Loss: 0.18451555678620934\n",
            "Epoch 2, Batch 500, Loss: 0.19413704082369804\n",
            "Epoch 2, Batch 600, Loss: 0.18245120249688626\n",
            "Epoch 2, Batch 700, Loss: 0.1646643778309226\n",
            "Epoch 2, Batch 800, Loss: 0.16791698545217515\n",
            "Epoch 2, Batch 900, Loss: 0.16642786737531423\n",
            "Epoch 3, Batch 100, Loss: 0.14530807988718153\n",
            "Epoch 3, Batch 200, Loss: 0.14295325916260482\n",
            "Epoch 3, Batch 300, Loss: 0.14824189875274896\n",
            "Epoch 3, Batch 400, Loss: 0.14814099416136742\n",
            "Epoch 3, Batch 500, Loss: 0.14002327013760804\n",
            "Epoch 3, Batch 600, Loss: 0.12924575408920647\n",
            "Epoch 3, Batch 700, Loss: 0.1385688734613359\n",
            "Epoch 3, Batch 800, Loss: 0.11694747261703015\n",
            "Epoch 3, Batch 900, Loss: 0.12660390423610807\n",
            "Epoch 4, Batch 100, Loss: 0.10421335578896106\n",
            "Epoch 4, Batch 200, Loss: 0.10190687217749655\n",
            "Epoch 4, Batch 300, Loss: 0.11715433215722441\n",
            "Epoch 4, Batch 400, Loss: 0.09983601629734039\n",
            "Epoch 4, Batch 500, Loss: 0.11077789483591914\n",
            "Epoch 4, Batch 600, Loss: 0.10485212041065096\n",
            "Epoch 4, Batch 700, Loss: 0.10642116442322731\n",
            "Epoch 4, Batch 800, Loss: 0.1221928396448493\n",
            "Epoch 4, Batch 900, Loss: 0.10204452227801085\n",
            "Epoch 5, Batch 100, Loss: 0.09291139651089907\n",
            "Epoch 5, Batch 200, Loss: 0.09140532994642854\n",
            "Epoch 5, Batch 300, Loss: 0.0910280491784215\n",
            "Epoch 5, Batch 400, Loss: 0.09261331952176988\n",
            "Epoch 5, Batch 500, Loss: 0.09174413892440497\n",
            "Epoch 5, Batch 600, Loss: 0.097751924386248\n",
            "Epoch 5, Batch 700, Loss: 0.08838684857822955\n",
            "Epoch 5, Batch 800, Loss: 0.08621818326413631\n",
            "Epoch 5, Batch 900, Loss: 0.09799044958315789\n",
            "Epoch 6, Batch 100, Loss: 0.07775309910997748\n",
            "Epoch 6, Batch 200, Loss: 0.07310557337477804\n",
            "Epoch 6, Batch 300, Loss: 0.08138188049197197\n",
            "Epoch 6, Batch 400, Loss: 0.07784996841102838\n",
            "Epoch 6, Batch 500, Loss: 0.08877707387320698\n",
            "Epoch 6, Batch 600, Loss: 0.07876549608074129\n",
            "Epoch 6, Batch 700, Loss: 0.08515412974637002\n",
            "Epoch 6, Batch 800, Loss: 0.08917345334310084\n",
            "Epoch 6, Batch 900, Loss: 0.08568665571976453\n",
            "Epoch 7, Batch 100, Loss: 0.06476609865669161\n",
            "Epoch 7, Batch 200, Loss: 0.08007084783865138\n",
            "Epoch 7, Batch 300, Loss: 0.06418745381990448\n",
            "Epoch 7, Batch 400, Loss: 0.07346245328430086\n",
            "Epoch 7, Batch 500, Loss: 0.07382846832741052\n",
            "Epoch 7, Batch 600, Loss: 0.06524839611258358\n",
            "Epoch 7, Batch 700, Loss: 0.07805682542733848\n",
            "Epoch 7, Batch 800, Loss: 0.07296824169345201\n",
            "Epoch 7, Batch 900, Loss: 0.07090259104734287\n",
            "Epoch 8, Batch 100, Loss: 0.06662465791217982\n",
            "Epoch 8, Batch 200, Loss: 0.05603962515247986\n",
            "Epoch 8, Batch 300, Loss: 0.06854379433905705\n",
            "Epoch 8, Batch 400, Loss: 0.05820776395499706\n",
            "Epoch 8, Batch 500, Loss: 0.06750587568851188\n",
            "Epoch 8, Batch 600, Loss: 0.06840984541922808\n",
            "Epoch 8, Batch 700, Loss: 0.07314809216652066\n",
            "Epoch 8, Batch 800, Loss: 0.07062791193369776\n",
            "Epoch 8, Batch 900, Loss: 0.06474626697367057\n",
            "Epoch 9, Batch 100, Loss: 0.0503762096283026\n",
            "Epoch 9, Batch 200, Loss: 0.06010906960815191\n",
            "Epoch 9, Batch 300, Loss: 0.04700978748267517\n",
            "Epoch 9, Batch 400, Loss: 0.04944688736926764\n",
            "Epoch 9, Batch 500, Loss: 0.06548265152378008\n",
            "Epoch 9, Batch 600, Loss: 0.06353079708991573\n",
            "Epoch 9, Batch 700, Loss: 0.062393209249712527\n",
            "Epoch 9, Batch 800, Loss: 0.06203096569515765\n",
            "Epoch 9, Batch 900, Loss: 0.07452095785643906\n",
            "Epoch 10, Batch 100, Loss: 0.03925782101461664\n",
            "Epoch 10, Batch 200, Loss: 0.04833545372239314\n",
            "Epoch 10, Batch 300, Loss: 0.052600634186528626\n",
            "Epoch 10, Batch 400, Loss: 0.05164900397416204\n",
            "Epoch 10, Batch 500, Loss: 0.04960626654094085\n",
            "Epoch 10, Batch 600, Loss: 0.059339881112100555\n",
            "Epoch 10, Batch 700, Loss: 0.05961372821358964\n",
            "Epoch 10, Batch 800, Loss: 0.0523906832979992\n",
            "Epoch 10, Batch 900, Loss: 0.05298635044600815\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the neural network\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ1Osg8MnMY-",
        "outputId": "8f377179-51f0-4d2a-906c-4beca76dea0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training set: 98.547%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy on training set: {round(correct / total * 100, 3)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DXPLgQJJ6Aq",
        "outputId": "33b21f12-d884-4cd3-a6d1-f6e7010cccda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 96.987%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy on test set: {round(correct / total * 100, 3)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "E1nluT6ALxSX"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model and store predictions\n",
        "model.eval()\n",
        "predictions = []\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        predictions.extend(predicted.numpy())  # Store predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "MvdJMXaMMvUD",
        "outputId": "842d8404-5e32-4c33-963d-9f4082245049"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get one test image and its label\n",
        "image, label = images[0], labels[0]\n",
        "\n",
        "# Reshape the image tensor to a 28x28 shape\n",
        "image = image.view(28, 28)\n",
        "\n",
        "# Convert the image tensor to a numpy array for visualization\n",
        "image_numpy = image.numpy()\n",
        "\n",
        "# Show the image\n",
        "plt.imshow(image_numpy, cmap='gray')\n",
        "plt.title(f'Predicted Label: {predictions[0]}, Actual Label: {label.item()}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSwtA2a1d-ec"
      },
      "source": [
        "# Step 3\n",
        "**Report on the results in terms of prediction accuracy on the train and test datasets:**\n",
        "- Accuracy on training set: 98.547%\n",
        "- Accuracy on test set: 96.987%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60C6nda6eLw4"
      },
      "source": [
        "# Step 4\n",
        "**Chosen Proposed modification:**\n",
        "- Increase the current number of nodes in the layer to 256\n",
        "\n",
        "**Hypothesize how it would change the performance results:**\n",
        "- Expectation is that the performance would be better. Increasing the number of units should increase the representation power of the model, and thus capture complex relationships between the input features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyVI6BfBeaNJ"
      },
      "source": [
        "# Step 5\n",
        "Modify the model based on the chosen method and train\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HRirZf5edZV",
        "outputId": "af540bf4-b0be-40bc-d7a9-7fc0e89fc23f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 0.8315333399176598\n",
            "Epoch 1, Batch 200, Loss: 0.3892825858294964\n",
            "Epoch 1, Batch 300, Loss: 0.3312388211488724\n",
            "Epoch 1, Batch 400, Loss: 0.29238864809274673\n",
            "Epoch 1, Batch 500, Loss: 0.25460391253232956\n",
            "Epoch 1, Batch 600, Loss: 0.23815783731639384\n",
            "Epoch 1, Batch 700, Loss: 0.20803514167666434\n",
            "Epoch 1, Batch 800, Loss: 0.18777876071631908\n",
            "Epoch 1, Batch 900, Loss: 0.1991307683289051\n",
            "Epoch 2, Batch 100, Loss: 0.16356412880122662\n",
            "Epoch 2, Batch 200, Loss: 0.15090241089463233\n",
            "Epoch 2, Batch 300, Loss: 0.1390621871314943\n",
            "Epoch 2, Batch 400, Loss: 0.1434594888985157\n",
            "Epoch 2, Batch 500, Loss: 0.1489667522534728\n",
            "Epoch 2, Batch 600, Loss: 0.14218306321650742\n",
            "Epoch 2, Batch 700, Loss: 0.1353009326197207\n",
            "Epoch 2, Batch 800, Loss: 0.14568932274356483\n",
            "Epoch 2, Batch 900, Loss: 0.1307685891725123\n",
            "Epoch 3, Batch 100, Loss: 0.11662997851148248\n",
            "Epoch 3, Batch 200, Loss: 0.11852314038202166\n",
            "Epoch 3, Batch 300, Loss: 0.10695866728201509\n",
            "Epoch 3, Batch 400, Loss: 0.10434953725896776\n",
            "Epoch 3, Batch 500, Loss: 0.10217945214360952\n",
            "Epoch 3, Batch 600, Loss: 0.10390370571985841\n",
            "Epoch 3, Batch 700, Loss: 0.10378297731280327\n",
            "Epoch 3, Batch 800, Loss: 0.10881766075268388\n",
            "Epoch 3, Batch 900, Loss: 0.09820088487584144\n",
            "Epoch 4, Batch 100, Loss: 0.0928465828858316\n",
            "Epoch 4, Batch 200, Loss: 0.08151468455325812\n",
            "Epoch 4, Batch 300, Loss: 0.0773810667777434\n",
            "Epoch 4, Batch 400, Loss: 0.08942119410261512\n",
            "Epoch 4, Batch 500, Loss: 0.09075508187524975\n",
            "Epoch 4, Batch 600, Loss: 0.11268579199910164\n",
            "Epoch 4, Batch 700, Loss: 0.07640957414638251\n",
            "Epoch 4, Batch 800, Loss: 0.08599008219316602\n",
            "Epoch 4, Batch 900, Loss: 0.07069642125163228\n",
            "Epoch 5, Batch 100, Loss: 0.07612278729211538\n",
            "Epoch 5, Batch 200, Loss: 0.0691708096349612\n",
            "Epoch 5, Batch 300, Loss: 0.08637477464741096\n",
            "Epoch 5, Batch 400, Loss: 0.07533965692389756\n",
            "Epoch 5, Batch 500, Loss: 0.07491635583108291\n",
            "Epoch 5, Batch 600, Loss: 0.07313145034946501\n",
            "Epoch 5, Batch 700, Loss: 0.07446946258656681\n",
            "Epoch 5, Batch 800, Loss: 0.06270789837930352\n",
            "Epoch 5, Batch 900, Loss: 0.08406618473585695\n",
            "Epoch 6, Batch 100, Loss: 0.054546973078977316\n",
            "Epoch 6, Batch 200, Loss: 0.05482961439993232\n",
            "Epoch 6, Batch 300, Loss: 0.05621736558154225\n",
            "Epoch 6, Batch 400, Loss: 0.07307907375041395\n",
            "Epoch 6, Batch 500, Loss: 0.057959231664426625\n",
            "Epoch 6, Batch 600, Loss: 0.05731749589089304\n",
            "Epoch 6, Batch 700, Loss: 0.0686611954588443\n",
            "Epoch 6, Batch 800, Loss: 0.08698589231818915\n",
            "Epoch 6, Batch 900, Loss: 0.07381805634126067\n",
            "Epoch 7, Batch 100, Loss: 0.04791958170942962\n",
            "Epoch 7, Batch 200, Loss: 0.056352536051999774\n",
            "Epoch 7, Batch 300, Loss: 0.05400302044348791\n",
            "Epoch 7, Batch 400, Loss: 0.059835347877815366\n",
            "Epoch 7, Batch 500, Loss: 0.05689573156880215\n",
            "Epoch 7, Batch 600, Loss: 0.04522379014757462\n",
            "Epoch 7, Batch 700, Loss: 0.056707184973638504\n",
            "Epoch 7, Batch 800, Loss: 0.05968102044425905\n",
            "Epoch 7, Batch 900, Loss: 0.06830618766602128\n",
            "Epoch 8, Batch 100, Loss: 0.04219352396205068\n",
            "Epoch 8, Batch 200, Loss: 0.04015614970703609\n",
            "Epoch 8, Batch 300, Loss: 0.049519132797140625\n",
            "Epoch 8, Batch 400, Loss: 0.048308824039995674\n",
            "Epoch 8, Batch 500, Loss: 0.0591182462265715\n",
            "Epoch 8, Batch 600, Loss: 0.05172630889574066\n",
            "Epoch 8, Batch 700, Loss: 0.05576264209114015\n",
            "Epoch 8, Batch 800, Loss: 0.05128044608864002\n",
            "Epoch 8, Batch 900, Loss: 0.05665939392289147\n",
            "Epoch 9, Batch 100, Loss: 0.025496594415744766\n",
            "Epoch 9, Batch 200, Loss: 0.03668254701886326\n",
            "Epoch 9, Batch 300, Loss: 0.048139228750951585\n",
            "Epoch 9, Batch 400, Loss: 0.036965990403550676\n",
            "Epoch 9, Batch 500, Loss: 0.040234799212776125\n",
            "Epoch 9, Batch 600, Loss: 0.05505650482024066\n",
            "Epoch 9, Batch 700, Loss: 0.047085062253754584\n",
            "Epoch 9, Batch 800, Loss: 0.049553749695187436\n",
            "Epoch 9, Batch 900, Loss: 0.04456985189113766\n",
            "Epoch 10, Batch 100, Loss: 0.037219762480817736\n",
            "Epoch 10, Batch 200, Loss: 0.03714082796708681\n",
            "Epoch 10, Batch 300, Loss: 0.03674164804397151\n",
            "Epoch 10, Batch 400, Loss: 0.03897200128005352\n",
            "Epoch 10, Batch 500, Loss: 0.03674115068744868\n",
            "Epoch 10, Batch 600, Loss: 0.04037624961638357\n",
            "Epoch 10, Batch 700, Loss: 0.04808993538841605\n",
            "Epoch 10, Batch 800, Loss: 0.038214951218687926\n",
            "Epoch 10, Batch 900, Loss: 0.038304387391544875\n",
            "Finished Training\n",
            "\n",
            "Accuracy on training set: 99.105%\n",
            "\n",
            "Accuracy on test set: 97.52%\n"
          ]
        }
      ],
      "source": [
        "# Define the neural network architecture\n",
        "class MLP2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP2, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the neural network\n",
        "model = MLP2()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the neural network\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Evaluate the model on train set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on training set: {round(correct / total * 100, 3)}%')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on test set: {round(correct / total * 100, 3)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzRBv0uEed_H"
      },
      "source": [
        "# Step 6\n",
        "**Report on the results of the modified model and if it matches your hypothesis:**\n",
        "- Accuracy on training set: 99.105%\n",
        "- Accuracy on test set: 97.52%\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNpUAk1SekeY"
      },
      "source": [
        "# Step 7\n",
        "Experiment with different optimizers, loss functions, dropout, and activation functions, and observe the change in performance as you tune these hyperparameters.\n",
        "\n",
        "**I iteratively experimented with various hyperparameters, such as optimizers, loss functions, dropout rates, and activation functions, adjusting them based on the outcomes of the preceding experiments to observe the impact on performance.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHtBeqnprYB9"
      },
      "source": [
        "## Experiment 1\n",
        "- Using LeakyRELU as the activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjqchekReoMW",
        "outputId": "545e8519-b36c-4256-caf2-c9357185a275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 0.7632160739600659\n",
            "Epoch 1, Batch 200, Loss: 0.39074928596615793\n",
            "Epoch 1, Batch 300, Loss: 0.3213037703931332\n",
            "Epoch 1, Batch 400, Loss: 0.25640905074775217\n",
            "Epoch 1, Batch 500, Loss: 0.24245190277695655\n",
            "Epoch 1, Batch 600, Loss: 0.20931258969008923\n",
            "Epoch 1, Batch 700, Loss: 0.20887336071580648\n",
            "Epoch 1, Batch 800, Loss: 0.1886785141006112\n",
            "Epoch 1, Batch 900, Loss: 0.18757147759199141\n",
            "Epoch 2, Batch 100, Loss: 0.14128543565049767\n",
            "Epoch 2, Batch 200, Loss: 0.14673436660319567\n",
            "Epoch 2, Batch 300, Loss: 0.13652560468763114\n",
            "Epoch 2, Batch 400, Loss: 0.13773572657257319\n",
            "Epoch 2, Batch 500, Loss: 0.13382803009822963\n",
            "Epoch 2, Batch 600, Loss: 0.12957379762083293\n",
            "Epoch 2, Batch 700, Loss: 0.14438747867010535\n",
            "Epoch 2, Batch 800, Loss: 0.13322317080572246\n",
            "Epoch 2, Batch 900, Loss: 0.12175315452739596\n",
            "Epoch 3, Batch 100, Loss: 0.09873482514172792\n",
            "Epoch 3, Batch 200, Loss: 0.09130225039087236\n",
            "Epoch 3, Batch 300, Loss: 0.1249994841683656\n",
            "Epoch 3, Batch 400, Loss: 0.10955851440317929\n",
            "Epoch 3, Batch 500, Loss: 0.10401487143710256\n",
            "Epoch 3, Batch 600, Loss: 0.1151032654941082\n",
            "Epoch 3, Batch 700, Loss: 0.11506371429190039\n",
            "Epoch 3, Batch 800, Loss: 0.11065184027887881\n",
            "Epoch 3, Batch 900, Loss: 0.09647981256246567\n",
            "Epoch 4, Batch 100, Loss: 0.07739383869804442\n",
            "Epoch 4, Batch 200, Loss: 0.07483613112941384\n",
            "Epoch 4, Batch 300, Loss: 0.08056098961271346\n",
            "Epoch 4, Batch 400, Loss: 0.09722494947258382\n",
            "Epoch 4, Batch 500, Loss: 0.0828476348798722\n",
            "Epoch 4, Batch 600, Loss: 0.08429664750350639\n",
            "Epoch 4, Batch 700, Loss: 0.09279217790812254\n",
            "Epoch 4, Batch 800, Loss: 0.09012521831784398\n",
            "Epoch 4, Batch 900, Loss: 0.08224166980013252\n",
            "Epoch 5, Batch 100, Loss: 0.0579814449348487\n",
            "Epoch 5, Batch 200, Loss: 0.06962821991182863\n",
            "Epoch 5, Batch 300, Loss: 0.07557651918381453\n",
            "Epoch 5, Batch 400, Loss: 0.07499260239303113\n",
            "Epoch 5, Batch 500, Loss: 0.07638551456388086\n",
            "Epoch 5, Batch 600, Loss: 0.07280036075972021\n",
            "Epoch 5, Batch 700, Loss: 0.07326028805691749\n",
            "Epoch 5, Batch 800, Loss: 0.07206554035888985\n",
            "Epoch 5, Batch 900, Loss: 0.07443103009369224\n",
            "Epoch 6, Batch 100, Loss: 0.05273988344240934\n",
            "Epoch 6, Batch 200, Loss: 0.0590145654277876\n",
            "Epoch 6, Batch 300, Loss: 0.06779640805441886\n",
            "Epoch 6, Batch 400, Loss: 0.06657050155103207\n",
            "Epoch 6, Batch 500, Loss: 0.06802588867489248\n",
            "Epoch 6, Batch 600, Loss: 0.06519317278871313\n",
            "Epoch 6, Batch 700, Loss: 0.07016593139152974\n",
            "Epoch 6, Batch 800, Loss: 0.06745459567813668\n",
            "Epoch 6, Batch 900, Loss: 0.06955112242838368\n",
            "Epoch 7, Batch 100, Loss: 0.052296474780887364\n",
            "Epoch 7, Batch 200, Loss: 0.04800575849483721\n",
            "Epoch 7, Batch 300, Loss: 0.0566616832849104\n",
            "Epoch 7, Batch 400, Loss: 0.05884141452959739\n",
            "Epoch 7, Batch 500, Loss: 0.0544525728339795\n",
            "Epoch 7, Batch 600, Loss: 0.06031709162518382\n",
            "Epoch 7, Batch 700, Loss: 0.06286693713977001\n",
            "Epoch 7, Batch 800, Loss: 0.05776356118614785\n",
            "Epoch 7, Batch 900, Loss: 0.060017008481081574\n",
            "Epoch 8, Batch 100, Loss: 0.04380330572137609\n",
            "Epoch 8, Batch 200, Loss: 0.05493287850171327\n",
            "Epoch 8, Batch 300, Loss: 0.04862100912840105\n",
            "Epoch 8, Batch 400, Loss: 0.050906454036012294\n",
            "Epoch 8, Batch 500, Loss: 0.05690437270037364\n",
            "Epoch 8, Batch 600, Loss: 0.05210633678711019\n",
            "Epoch 8, Batch 700, Loss: 0.05558749839197844\n",
            "Epoch 8, Batch 800, Loss: 0.05304075084626675\n",
            "Epoch 8, Batch 900, Loss: 0.05690860635484569\n",
            "Epoch 9, Batch 100, Loss: 0.03696327087120153\n",
            "Epoch 9, Batch 200, Loss: 0.04064243300119415\n",
            "Epoch 9, Batch 300, Loss: 0.04487080092250835\n",
            "Epoch 9, Batch 400, Loss: 0.05320825085917022\n",
            "Epoch 9, Batch 500, Loss: 0.040679682787740604\n",
            "Epoch 9, Batch 600, Loss: 0.03817495876282919\n",
            "Epoch 9, Batch 700, Loss: 0.07227023900486529\n",
            "Epoch 9, Batch 800, Loss: 0.0704865946865175\n",
            "Epoch 9, Batch 900, Loss: 0.054486140196677295\n",
            "Epoch 10, Batch 100, Loss: 0.03307107194908895\n",
            "Epoch 10, Batch 200, Loss: 0.04140308475238271\n",
            "Epoch 10, Batch 300, Loss: 0.030779009243706242\n",
            "Epoch 10, Batch 400, Loss: 0.04382532971241744\n",
            "Epoch 10, Batch 500, Loss: 0.046505598508520055\n",
            "Epoch 10, Batch 600, Loss: 0.042793199848383666\n",
            "Epoch 10, Batch 700, Loss: 0.049179610200226306\n",
            "Epoch 10, Batch 800, Loss: 0.053590977806597946\n",
            "Epoch 10, Batch 900, Loss: 0.06367366649559698\n",
            "Finished Training\n",
            "\n",
            "Accuracy on training set: 98.858%\n",
            "\n",
            "Accuracy on test set: 97.272%\n"
          ]
        }
      ],
      "source": [
        "# Define the neural network architecture\n",
        "class MLP3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP3, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        m = nn.LeakyReLU(0.1)\n",
        "        x = m(self.fc1(x))\n",
        "        x = m(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the neural network\n",
        "model = MLP3()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the neural network\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Evaluate the model on train set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on training set: {round(correct / total * 100, 3)}%')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on test set: {round(correct / total * 100, 3)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vLdDwuus_ad"
      },
      "source": [
        "**EExperiment 1, Finding: The model's performance showed very slight alterations.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnqjuR3ZtLIc"
      },
      "source": [
        "## Experiment 2\n",
        "- Adding dropout\n",
        "- Using RELU as activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2qd9sTctKft",
        "outputId": "af89efb2-5496-49e7-b7e5-87f461b41edc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 1.1301324105262756\n",
            "Epoch 1, Batch 200, Loss: 0.5579663163423538\n",
            "Epoch 1, Batch 300, Loss: 0.4410348604619503\n",
            "Epoch 1, Batch 400, Loss: 0.42716115832328794\n",
            "Epoch 1, Batch 500, Loss: 0.39324299186468126\n",
            "Epoch 1, Batch 600, Loss: 0.3758322285115719\n",
            "Epoch 1, Batch 700, Loss: 0.35866938367486\n",
            "Epoch 1, Batch 800, Loss: 0.3222226497530937\n",
            "Epoch 1, Batch 900, Loss: 0.309950697645545\n",
            "Epoch 2, Batch 100, Loss: 0.30416439563035963\n",
            "Epoch 2, Batch 200, Loss: 0.3162388395518064\n",
            "Epoch 2, Batch 300, Loss: 0.27295483633875844\n",
            "Epoch 2, Batch 400, Loss: 0.25656445875763895\n",
            "Epoch 2, Batch 500, Loss: 0.2626371325179935\n",
            "Epoch 2, Batch 600, Loss: 0.2718454971909523\n",
            "Epoch 2, Batch 700, Loss: 0.2693655971437693\n",
            "Epoch 2, Batch 800, Loss: 0.2443015395104885\n",
            "Epoch 2, Batch 900, Loss: 0.238337564393878\n",
            "Epoch 3, Batch 100, Loss: 0.23580751232802868\n",
            "Epoch 3, Batch 200, Loss: 0.23377230532467366\n",
            "Epoch 3, Batch 300, Loss: 0.23278517082333564\n",
            "Epoch 3, Batch 400, Loss: 0.22495040286332368\n",
            "Epoch 3, Batch 500, Loss: 0.2500786595791578\n",
            "Epoch 3, Batch 600, Loss: 0.2283159377425909\n",
            "Epoch 3, Batch 700, Loss: 0.22146965883672237\n",
            "Epoch 3, Batch 800, Loss: 0.24177339538931847\n",
            "Epoch 3, Batch 900, Loss: 0.22338032934814692\n",
            "Epoch 4, Batch 100, Loss: 0.2207101561501622\n",
            "Epoch 4, Batch 200, Loss: 0.20789026204496622\n",
            "Epoch 4, Batch 300, Loss: 0.22313828859478235\n",
            "Epoch 4, Batch 400, Loss: 0.20406753515824674\n",
            "Epoch 4, Batch 500, Loss: 0.1998004169948399\n",
            "Epoch 4, Batch 600, Loss: 0.20395512335002422\n",
            "Epoch 4, Batch 700, Loss: 0.19909961055964231\n",
            "Epoch 4, Batch 800, Loss: 0.21561504632234574\n",
            "Epoch 4, Batch 900, Loss: 0.212048696950078\n",
            "Epoch 5, Batch 100, Loss: 0.20640271496027707\n",
            "Epoch 5, Batch 200, Loss: 0.19721390599384903\n",
            "Epoch 5, Batch 300, Loss: 0.2015337421093136\n",
            "Epoch 5, Batch 400, Loss: 0.19274215441197157\n",
            "Epoch 5, Batch 500, Loss: 0.19127178650349377\n",
            "Epoch 5, Batch 600, Loss: 0.18990719318389893\n",
            "Epoch 5, Batch 700, Loss: 0.19008890483528376\n",
            "Epoch 5, Batch 800, Loss: 0.19006519228219987\n",
            "Epoch 5, Batch 900, Loss: 0.1922839469090104\n",
            "Epoch 6, Batch 100, Loss: 0.19225139826536178\n",
            "Epoch 6, Batch 200, Loss: 0.20135176744312047\n",
            "Epoch 6, Batch 300, Loss: 0.1799675191193819\n",
            "Epoch 6, Batch 400, Loss: 0.1854833898320794\n",
            "Epoch 6, Batch 500, Loss: 0.18022851184010505\n",
            "Epoch 6, Batch 600, Loss: 0.17550670374184846\n",
            "Epoch 6, Batch 700, Loss: 0.17072294596582652\n",
            "Epoch 6, Batch 800, Loss: 0.2020345639437437\n",
            "Epoch 6, Batch 900, Loss: 0.19563283313065769\n",
            "Epoch 7, Batch 100, Loss: 0.1820600875839591\n",
            "Epoch 7, Batch 200, Loss: 0.17381619539111853\n",
            "Epoch 7, Batch 300, Loss: 0.16813043788075446\n",
            "Epoch 7, Batch 400, Loss: 0.17479976695030927\n",
            "Epoch 7, Batch 500, Loss: 0.19064446952193975\n",
            "Epoch 7, Batch 600, Loss: 0.16893525768071413\n",
            "Epoch 7, Batch 700, Loss: 0.17939930766820908\n",
            "Epoch 7, Batch 800, Loss: 0.18523068057373165\n",
            "Epoch 7, Batch 900, Loss: 0.16537558924406767\n",
            "Epoch 8, Batch 100, Loss: 0.17419889688491821\n",
            "Epoch 8, Batch 200, Loss: 0.1619646790996194\n",
            "Epoch 8, Batch 300, Loss: 0.1597123521193862\n",
            "Epoch 8, Batch 400, Loss: 0.15636237598955632\n",
            "Epoch 8, Batch 500, Loss: 0.18047496441751718\n",
            "Epoch 8, Batch 600, Loss: 0.16454665871337057\n",
            "Epoch 8, Batch 700, Loss: 0.16617594338953495\n",
            "Epoch 8, Batch 800, Loss: 0.17190407684072853\n",
            "Epoch 8, Batch 900, Loss: 0.16553398313000797\n",
            "Epoch 9, Batch 100, Loss: 0.16486388685181738\n",
            "Epoch 9, Batch 200, Loss: 0.1572630924731493\n",
            "Epoch 9, Batch 300, Loss: 0.1636925997585058\n",
            "Epoch 9, Batch 400, Loss: 0.1706784223392606\n",
            "Epoch 9, Batch 500, Loss: 0.16337714804336428\n",
            "Epoch 9, Batch 600, Loss: 0.15071498185396195\n",
            "Epoch 9, Batch 700, Loss: 0.14935146786272527\n",
            "Epoch 9, Batch 800, Loss: 0.16795979686081408\n",
            "Epoch 9, Batch 900, Loss: 0.168104260917753\n",
            "Epoch 10, Batch 100, Loss: 0.1418464858084917\n",
            "Epoch 10, Batch 200, Loss: 0.15649175843223928\n",
            "Epoch 10, Batch 300, Loss: 0.14377535965293645\n",
            "Epoch 10, Batch 400, Loss: 0.1703435742482543\n",
            "Epoch 10, Batch 500, Loss: 0.1626422229409218\n",
            "Epoch 10, Batch 600, Loss: 0.154192253947258\n",
            "Epoch 10, Batch 700, Loss: 0.14908742593601346\n",
            "Epoch 10, Batch 800, Loss: 0.15431055093184112\n",
            "Epoch 10, Batch 900, Loss: 0.1783814922347665\n",
            "Finished Training\n",
            "\n",
            "Accuracy on training set: 97.798%\n",
            "\n",
            "Accuracy on test set: 96.82%\n"
          ]
        }
      ],
      "source": [
        "# Define the neural network architecture\n",
        "class MLP4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP4, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the neural network\n",
        "model = MLP4()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the neural network\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Evaluate the model on train set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on training set: {round(correct / total * 100, 3)}%')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on test set: {round(correct / total * 100, 3)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNwt_5aavmPj"
      },
      "source": [
        "**Experiment 2, Observation: Very slight change in model performance here aswell (similar with experiment 1).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoTKZ3fFv03A"
      },
      "source": [
        "## Experiment 2\n",
        "- Optimizer : SGD with Momentum\n",
        "- Remove Dropout\n",
        "- Keep Loss Function as it is. (CrossEntropyLoss is a good loss function for image classification tasks)\n",
        "- Change epochs to 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2ZSDNhSwELr",
        "outputId": "040445bf-1f00-49d4-f16d-02e87f38e37f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 2.224481210708618\n",
            "Epoch 1, Batch 200, Loss: 1.9270283818244933\n",
            "Epoch 1, Batch 300, Loss: 1.3797918730974197\n",
            "Epoch 1, Batch 400, Loss: 0.9533278000354767\n",
            "Epoch 1, Batch 500, Loss: 0.7103223320841789\n",
            "Epoch 1, Batch 600, Loss: 0.5965730234980583\n",
            "Epoch 1, Batch 700, Loss: 0.5220018112659455\n",
            "Epoch 1, Batch 800, Loss: 0.4797197350859642\n",
            "Epoch 1, Batch 900, Loss: 0.4348887175321579\n",
            "Epoch 2, Batch 100, Loss: 0.41229547426104546\n",
            "Epoch 2, Batch 200, Loss: 0.39053060963749886\n",
            "Epoch 2, Batch 300, Loss: 0.38432685181498527\n",
            "Epoch 2, Batch 400, Loss: 0.35867737501859664\n",
            "Epoch 2, Batch 500, Loss: 0.3665939424932003\n",
            "Epoch 2, Batch 600, Loss: 0.3753409294784069\n",
            "Epoch 2, Batch 700, Loss: 0.34949454620480536\n",
            "Epoch 2, Batch 800, Loss: 0.3416540056467056\n",
            "Epoch 2, Batch 900, Loss: 0.3300665873289108\n",
            "Epoch 3, Batch 100, Loss: 0.3471053323149681\n",
            "Epoch 3, Batch 200, Loss: 0.34517440780997277\n",
            "Epoch 3, Batch 300, Loss: 0.31204001858830455\n",
            "Epoch 3, Batch 400, Loss: 0.32280624479055403\n",
            "Epoch 3, Batch 500, Loss: 0.29858220741152763\n",
            "Epoch 3, Batch 600, Loss: 0.2938095434010029\n",
            "Epoch 3, Batch 700, Loss: 0.3011746067553759\n",
            "Epoch 3, Batch 800, Loss: 0.3061136271804571\n",
            "Epoch 3, Batch 900, Loss: 0.2990823109447956\n",
            "Epoch 4, Batch 100, Loss: 0.2977969065308571\n",
            "Epoch 4, Batch 200, Loss: 0.289566588550806\n",
            "Epoch 4, Batch 300, Loss: 0.29094085201621056\n",
            "Epoch 4, Batch 400, Loss: 0.28548889234662056\n",
            "Epoch 4, Batch 500, Loss: 0.2784247837215662\n",
            "Epoch 4, Batch 600, Loss: 0.2817602883279324\n",
            "Epoch 4, Batch 700, Loss: 0.28624541334807874\n",
            "Epoch 4, Batch 800, Loss: 0.27497914046049116\n",
            "Epoch 4, Batch 900, Loss: 0.2714167831093073\n",
            "Epoch 5, Batch 100, Loss: 0.26403513595461847\n",
            "Epoch 5, Batch 200, Loss: 0.2747901678830385\n",
            "Epoch 5, Batch 300, Loss: 0.2478889002650976\n",
            "Epoch 5, Batch 400, Loss: 0.2509042101353407\n",
            "Epoch 5, Batch 500, Loss: 0.2707058796286583\n",
            "Epoch 5, Batch 600, Loss: 0.2547260344028473\n",
            "Epoch 5, Batch 700, Loss: 0.2639049129188061\n",
            "Epoch 5, Batch 800, Loss: 0.24450028590857983\n",
            "Epoch 5, Batch 900, Loss: 0.2539247103780508\n",
            "Epoch 6, Batch 100, Loss: 0.21968462333083152\n",
            "Epoch 6, Batch 200, Loss: 0.26143161799758674\n",
            "Epoch 6, Batch 300, Loss: 0.237280877456069\n",
            "Epoch 6, Batch 400, Loss: 0.2378515662252903\n",
            "Epoch 6, Batch 500, Loss: 0.2423847432807088\n",
            "Epoch 6, Batch 600, Loss: 0.22766771651804446\n",
            "Epoch 6, Batch 700, Loss: 0.23804111286997795\n",
            "Epoch 6, Batch 800, Loss: 0.2369661721587181\n",
            "Epoch 6, Batch 900, Loss: 0.2277098923921585\n",
            "Epoch 7, Batch 100, Loss: 0.22245338886976243\n",
            "Epoch 7, Batch 200, Loss: 0.2264345270767808\n",
            "Epoch 7, Batch 300, Loss: 0.2159179487079382\n",
            "Epoch 7, Batch 400, Loss: 0.23512667682021857\n",
            "Epoch 7, Batch 500, Loss: 0.22873317301273347\n",
            "Epoch 7, Batch 600, Loss: 0.2209105349704623\n",
            "Epoch 7, Batch 700, Loss: 0.21302233465015888\n",
            "Epoch 7, Batch 800, Loss: 0.19689943373203278\n",
            "Epoch 7, Batch 900, Loss: 0.20591405227780343\n",
            "Epoch 8, Batch 100, Loss: 0.20858232393860818\n",
            "Epoch 8, Batch 200, Loss: 0.20112696617841722\n",
            "Epoch 8, Batch 300, Loss: 0.21119781009852887\n",
            "Epoch 8, Batch 400, Loss: 0.19671707943081856\n",
            "Epoch 8, Batch 500, Loss: 0.2072825477272272\n",
            "Epoch 8, Batch 600, Loss: 0.2029049926251173\n",
            "Epoch 8, Batch 700, Loss: 0.19730667300522328\n",
            "Epoch 8, Batch 800, Loss: 0.1973567495495081\n",
            "Epoch 8, Batch 900, Loss: 0.18383193127810954\n",
            "Epoch 9, Batch 100, Loss: 0.19539404548704625\n",
            "Epoch 9, Batch 200, Loss: 0.1852286897599697\n",
            "Epoch 9, Batch 300, Loss: 0.18016495514661074\n",
            "Epoch 9, Batch 400, Loss: 0.18611078664660455\n",
            "Epoch 9, Batch 500, Loss: 0.20205489829182624\n",
            "Epoch 9, Batch 600, Loss: 0.19575602982193233\n",
            "Epoch 9, Batch 700, Loss: 0.17485307581722737\n",
            "Epoch 9, Batch 800, Loss: 0.1860354572534561\n",
            "Epoch 9, Batch 900, Loss: 0.17310044903308153\n",
            "Epoch 10, Batch 100, Loss: 0.17530674990266562\n",
            "Epoch 10, Batch 200, Loss: 0.16490042373538016\n",
            "Epoch 10, Batch 300, Loss: 0.17012056563049555\n",
            "Epoch 10, Batch 400, Loss: 0.17374056689441203\n",
            "Epoch 10, Batch 500, Loss: 0.18730209432542325\n",
            "Epoch 10, Batch 600, Loss: 0.15776211943477392\n",
            "Epoch 10, Batch 700, Loss: 0.17595849391072987\n",
            "Epoch 10, Batch 800, Loss: 0.16299772270023824\n",
            "Epoch 10, Batch 900, Loss: 0.17590838253498078\n",
            "Finished Training\n",
            "\n",
            "Accuracy on training set: 95.348%\n",
            "\n",
            "Accuracy on test set: 94.765%\n"
          ]
        }
      ],
      "source": [
        "# Define the neural network architecture\n",
        "class MLP5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP5, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the neural network\n",
        "model = MLP5()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the neural network\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Evaluate the model on train set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on training set: {round(correct / total * 100, 3)}%')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on test set: {round(correct / total * 100, 3)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHoJud-oyCYG"
      },
      "source": [
        "##### **Experiment 3, Result: The observed decrease in model performance indicates that Adam significantly outperforms SGD with momentum.** **bold text**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}